{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed: NG4995_RCL5_masked.nrrd -> NG4995_RCL5_0000.nrrd\n",
      "Renamed: NG4995_Segments.seg.nrrd -> NG4995_RCL5.seg.nrrd\n",
      "Renamed: NG4996_RCL5_masked.nrrd -> NG4996_RCL5_0000.nrrd\n",
      "Renamed: NG4996_Segments.seg.nrrd -> NG4996_RCL5.seg.nrrd\n",
      "Renamed: NG4997_RCL5_masked.nrrd -> NG4997_RCL5_0000.nrrd\n",
      "Renamed: NG4997_Segments.seg.nrrd -> NG4997_RCL5.seg.nrrd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/extra_data/file_arrangements\"\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    old_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    if file_name.endswith(\"masked.nrrd\"):\n",
    "        parts = file_name.split(\"_\")\n",
    "        if len(parts) >= 2:\n",
    "            new_name = f\"{parts[0]}_{parts[1]}_0000.nrrd\"\n",
    "            new_path = os.path.join(folder_path, new_name)\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"Renamed: {file_name} -> {new_name}\")\n",
    "\n",
    "    elif file_name.endswith(\"seg.nrrd\"):\n",
    "        parts = file_name.split(\"_\")\n",
    "        if len(parts) >= 1:\n",
    "            new_name = f\"{parts[0]}_RCL5.seg.nrrd\"\n",
    "            new_path = os.path.join(folder_path, new_name)\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"Renamed: {file_name} -> {new_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path arrangements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np \n",
    "import nrrd\n",
    "import re\n",
    "from typing import Tuple\n",
    "import csv\n",
    "from os.path import join\n",
    "from utils.helper import convert_file_format, make_if_dont_exist,convert_file_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset path\n",
    "BASE_PATH = Path('./').resolve()\n",
    "DATA_PATH = BASE_PATH / 'dataset'\n",
    "\n",
    "project_name = 'first'  # Change here for different task names\n",
    "task_name = 'Dataset004_' + project_name\n",
    "\n",
    "TRAINING_DATASET_PATH = BASE_PATH / 'dataset/nnUNet_raw_data' / task_name / 'imagesTr'\n",
    "GT_TRAINING_DATASET_PATH = BASE_PATH / 'dataset/nnUNet_raw_data' / task_name / 'labelsTr'  # Only nii.gz labels\n",
    "GT_TRAINING_LABELS_PATH = BASE_PATH / 'dataset/nnUNet_raw_data' / 'extracting_labels'  # Store .nrrd label maps separately\n",
    "TEST_DATASET_PATH = BASE_PATH / 'dataset/nnUNet_raw_data' / task_name / 'imagesTs'\n",
    "\n",
    "PREDICTION_RESULTS_PATH = BASE_PATH / 'dataset/nnUNet_Prediction_Results' / task_name\n",
    "TASK_PATH = BASE_PATH / 'dataset/nnUNet_raw_data' / task_name\n",
    "\n",
    "# setup environment variables\n",
    "nnUNet_raw = BASE_PATH / 'dataset/nnUNet_raw_data'\n",
    "nnUNet_preprocessed = BASE_PATH / 'dataset/nnUNet_preprocessed'\n",
    "nnUNet_results = BASE_PATH / 'dataset/nnUNet_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_if_dont_exist(TRAINING_DATASET_PATH,overwrite=False)\n",
    "make_if_dont_exist(GT_TRAINING_DATASET_PATH)\n",
    "make_if_dont_exist(TEST_DATASET_PATH)\n",
    "\n",
    "make_if_dont_exist(PREDICTION_RESULTS_PATH)\n",
    "\n",
    "make_if_dont_exist(nnUNet_preprocessed)\n",
    "make_if_dont_exist(nnUNet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image files: 11\n",
      "train label files: 11\n",
      "Matches: 0\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(TRAINING_DATASET_PATH)\n",
    "label_files = os.listdir(GT_TRAINING_DATASET_PATH)\n",
    "print(\"train image files:\",len(train_files))\n",
    "print(\"train label files:\",len(label_files))\n",
    "print(\"Matches:\",len(set(train_files).intersection(set(label_files))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert File Format to nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_file_format(TRAINING_DATASET_PATH, TRAINING_DATASET_PATH, '.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convert_file_format(TEST_DATASET_PATH, TEST_DATASET_PATH, '.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convert_file_format(GT_TRAINING_DATASET_PATH, GT_TRAINING_DATASET_PATH, '.nrrd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nrrd\n",
    "import torch\n",
    "\n",
    "file_path = \"/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nrrd/NG2561_Segments_left.seg.nrrd\"\n",
    "data, header = nrrd.read(file_path)\n",
    "\n",
    "# Convert data to tensor\n",
    "tensor_data = torch.tensor(data, dtype=torch.float32)\n",
    "unique_labels = torch.unique(tensor_data)\n",
    "\n",
    "# Print all metadata\n",
    "print(\"NRRD Metadata:\")\n",
    "for key, value in header.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Extract label names\n",
    "label_names = {key.split('_')[0]: value for key, value in header.items() if key.endswith(\"_Name\")}\n",
    "\n",
    "# Extract corresponding intensity values from LabelValue\n",
    "intensity_levels = {\n",
    "    key.split('_')[0]: value for key, value in header.items() if key.endswith(\"_\")\n",
    "}\n",
    "\n",
    "# Ensure intensity values are numeric and map them to labels\n",
    "label_intensity_mapping = {\n",
    "    label_names[key]: int(intensity_levels[key])\n",
    "    for key in label_names if key in intensity_levels and str(intensity_levels[key]).isdigit()\n",
    "}\n",
    "\n",
    "print(f\"{file_path}:\", label_intensity_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/segment_labels.csv' has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "folder_path = GT_TRAINING_LABELS_PATH\n",
    "output_csv = \"/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/segment_labels.csv\"  # Output CSV file name\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(output_csv, mode=\"w\", newline=\"\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    # Write the header row\n",
    "    csv_writer.writerow([\"Filename\", \"Segment Number\", \"Label Name\"])\n",
    "    \n",
    "    # Loop through the folder and process seg.nrrd files\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\"seg.nrrd\"):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            data, header = nrrd.read(file_path)\n",
    "\n",
    "            # Extract label names\n",
    "            label_names = {key.split('_')[0]: value for key, value in header.items() if key.endswith(\"_Name\")}\n",
    "            \n",
    "            # Process and extract numbers\n",
    "            for key, value in label_names.items():\n",
    "                match = re.match(r\"Segment(\\d+)\", key)  # Extract digits after \"Segment\"\n",
    "                if match:\n",
    "                    segment_number = match.group(1)  # Extracted number as string\n",
    "                    csv_writer.writerow([file, segment_number, value])  # Write to CSV\n",
    "\n",
    "print(f\"CSV file '{output_csv}' has been created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'background': 0, 'f': 10, 'st': 11, 'ic': 12, 'och': 13, 'ac': 14, 'fr': 15, 'Hb': 16, 'TH': 17, 'MB': 18, 'HY': 19, 'CTX+': 1, 'P': 20, 'MY': 21, 'Cerebellum_AV': 22, 'Cerebellum_GL': 23, 'Cerebellum_ML': 24, 'V': 25, 'OB': 26, 'border': 27, 'cc+': 2, 'CPu': 3, 'DG': 4, 'HP': 5, 'RHP': 6, 'A': 7, 'ig': 8, 'fi': 9}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to save JSON\n",
    "def save_json(data, file_path, sort_keys=False):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f, indent=4, sort_keys=sort_keys)\n",
    "def generate_dataset_json(output_folder: str,\n",
    "                          channel_names: dict,\n",
    "                          labels: dict,\n",
    "                          num_training_cases: int,\n",
    "                          file_ending: str,\n",
    "                          regions_class_order: Tuple[int, ...] = None,\n",
    "                          dataset_name: str = None, reference: str = None, release: str = None, license: str = None,\n",
    "                          description: str = None,\n",
    "                          overwrite_image_reader_writer: str = None, **kwargs):\n",
    "    \n",
    "    has_regions: bool = any([isinstance(i, (tuple, list)) and len(i) > 1 for i in labels.values()])\n",
    "    if has_regions:\n",
    "        assert regions_class_order is not None, f\"You have defined regions but regions_class_order is not set. \" \\\n",
    "                                                f\"You need that.\"\n",
    "    # channel names need strings as keys\n",
    "    keys = list(channel_names.keys())\n",
    "    for k in keys:\n",
    "        if not isinstance(k, str):\n",
    "            channel_names[str(k)] = channel_names[k]\n",
    "            del channel_names[k]\n",
    "\n",
    "    # labels need ints as values\n",
    "    for l in labels.keys():\n",
    "        value = labels[l]\n",
    "        if isinstance(value, (tuple, list)):\n",
    "            value = tuple([int(i) for i in value])\n",
    "            labels[l] = value\n",
    "        else:\n",
    "            labels[l] = int(labels[l])\n",
    "\n",
    "    dataset_json = {\n",
    "        'channel_names': channel_names,  # previously this was called 'modality'. I didn't like this so this is\n",
    "        # channel_names now. Live with it.\n",
    "        'labels': labels,\n",
    "        'numTraining': num_training_cases,\n",
    "        'file_ending': file_ending,\n",
    "    }\n",
    "\n",
    "    if dataset_name is not None:\n",
    "        dataset_json['name'] = dataset_name\n",
    "    if reference is not None:\n",
    "        dataset_json['reference'] = reference\n",
    "    if release is not None:\n",
    "        dataset_json['release'] = release\n",
    "    if license is not None:\n",
    "        dataset_json['licence'] = license\n",
    "    if description is not None:\n",
    "        dataset_json['description'] = description\n",
    "    if overwrite_image_reader_writer is not None:\n",
    "        dataset_json['overwrite_image_reader_writer'] = overwrite_image_reader_writer\n",
    "    if regions_class_order is not None:\n",
    "        dataset_json['regions_class_order'] = regions_class_order\n",
    "\n",
    "    dataset_json.update(kwargs)\n",
    "\n",
    "    save_json(dataset_json, join(output_folder, 'dataset.json'), sort_keys=False)\n",
    "# Extract label names dynamically from .nrrd files in extracting_labels folder\n",
    "def extract_labels_from_nrrd(folder_path):\n",
    "    label_dict = {\"background\": 0}  # Ensure background is always labeled as 0\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".seg.nrrd\"):  # Process only segmentation nrrd files\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            data, header = nrrd.read(file_path)\n",
    "\n",
    "            # Extract segment numbers and names\n",
    "            for key, value in header.items():\n",
    "                if key.endswith(\"_Name\"):\n",
    "                    match = re.match(r\"Segment(\\d+)\", key)  # Extract segment number\n",
    "                    if match:\n",
    "                        segment_number = int(match.group(1))\n",
    "                        if value.lower() != \"mask\":  # Exclude \"mask\"\n",
    "                            label_dict[value] = segment_number  \n",
    "\n",
    "    return label_dict\n",
    "\n",
    "# Extract labels dynamically, ensuring \"mask\" is not included\n",
    "labels = extract_labels_from_nrrd(GT_TRAINING_LABELS_PATH)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save JSON\n",
    "def save_json(data, file_path, sort_keys=False):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f, indent=4, sort_keys=sort_keys)\n",
    "def generate_dataset_json(output_folder: str,\n",
    "                          channel_names: dict,\n",
    "                          labels: dict,\n",
    "                          num_training_cases: int,\n",
    "                          file_ending: str,\n",
    "                          regions_class_order: Tuple[int, ...] = None,\n",
    "                          dataset_name: str = None, reference: str = None, release: str = None, license: str = None,\n",
    "                          description: str = None,\n",
    "                          overwrite_image_reader_writer: str = None, **kwargs):\n",
    "    \n",
    "    has_regions: bool = any([isinstance(i, (tuple, list)) and len(i) > 1 for i in labels.values()])\n",
    "    if has_regions:\n",
    "        assert regions_class_order is not None, f\"You have defined regions but regions_class_order is not set. \" \\\n",
    "                                                f\"You need that.\"\n",
    "    # channel names need strings as keys\n",
    "    keys = list(channel_names.keys())\n",
    "    for k in keys:\n",
    "        if not isinstance(k, str):\n",
    "            channel_names[str(k)] = channel_names[k]\n",
    "            del channel_names[k]\n",
    "\n",
    "    # labels need ints as values\n",
    "    for l in labels.keys():\n",
    "        value = labels[l]\n",
    "        if isinstance(value, (tuple, list)):\n",
    "            value = tuple([int(i) for i in value])\n",
    "            labels[l] = value\n",
    "        else:\n",
    "            labels[l] = int(labels[l])\n",
    "\n",
    "    dataset_json = {\n",
    "        'channel_names': channel_names,  # previously this was called 'modality'. I didn't like this so this is\n",
    "        # channel_names now. Live with it.\n",
    "        'labels': labels,\n",
    "        'numTraining': num_training_cases,\n",
    "        'file_ending': file_ending,\n",
    "    }\n",
    "\n",
    "    if dataset_name is not None:\n",
    "        dataset_json['name'] = dataset_name\n",
    "    if reference is not None:\n",
    "        dataset_json['reference'] = reference\n",
    "    if release is not None:\n",
    "        dataset_json['release'] = release\n",
    "    if license is not None:\n",
    "        dataset_json['licence'] = license\n",
    "    if description is not None:\n",
    "        dataset_json['description'] = description\n",
    "    if overwrite_image_reader_writer is not None:\n",
    "        dataset_json['overwrite_image_reader_writer'] = overwrite_image_reader_writer\n",
    "    if regions_class_order is not None:\n",
    "        dataset_json['regions_class_order'] = regions_class_order\n",
    "\n",
    "    dataset_json.update(kwargs)\n",
    "\n",
    "    save_json(dataset_json, join(output_folder, 'dataset.json'), sort_keys=False)\n",
    "# Extract label names dynamically from .nrrd files in extracting_labels folder\n",
    "def extract_labels_from_nrrd(folder_path):\n",
    "    label_dict = {\"background\": 0}  # Ensure background is always labeled as 0\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".seg.nrrd\"):  # Process only segmentation nrrd files\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            data, header = nrrd.read(file_path)\n",
    "\n",
    "            # Extract segment numbers and names\n",
    "            for key, value in header.items():\n",
    "                if key.endswith(\"_Name\"):\n",
    "                    match = re.match(r\"Segment(\\d+)\", key)  # Extract segment number\n",
    "                    if match:\n",
    "                        segment_number = int(match.group(1))\n",
    "                        if value.lower() != \"mask\":  # Exclude \"mask\"\n",
    "                            label_dict[value] = segment_number  \n",
    "\n",
    "    return label_dict\n",
    "\n",
    "# Extract labels dynamically, ensuring \"mask\" is not included\n",
    "labels = extract_labels_from_nrrd(GT_TRAINING_LABELS_PATH)\n",
    "\n",
    "# List all nii.gz label files (ignore .nrrd files)\n",
    "image_files = sorted(os.listdir(TRAINING_DATASET_PATH))\n",
    "label_files = sorted(f for f in os.listdir(GT_TRAINING_DATASET_PATH) if f.endswith(\".nii.gz\"))\n",
    "test_ids = sorted(os.listdir(TEST_DATASET_PATH))\n",
    "\n",
    "channel_names = {\"0\": \"microscopic\"}\n",
    "num_training_cases = len(image_files)\n",
    "file_ending = \".nii.gz\"\n",
    "\n",
    "# Generate dataset.json dynamically\n",
    "generate_dataset_json(\n",
    "    output_folder=TASK_PATH,\n",
    "    channel_names=channel_names,\n",
    "    labels=labels,  # Now \"mask\" is excluded\n",
    "    num_training_cases=num_training_cases,\n",
    "    file_ending=file_ending,\n",
    "    dataset_name=\"Mouse Brain Segmentation\",\n",
    "    description=\"Mouse Brain Segmentation\",\n",
    "    reference=\"\",\n",
    "    release=\"0.0\",\n",
    "    license=\"\",\n",
    "    training=[\n",
    "        {'image': f\"./imagesTr/{image_file}\", 'label': f\"./labelsTr/{label_file}\"}\n",
    "        for image_file, label_file in zip(image_files, label_files)\n",
    "    ],\n",
    "    test=[\"./imagesTs/%s\" % (i[:i.find(\"_0000\")] + '.nii.gz') for i in test_ids]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remap nifti files (fixing label matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing labels in: /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4988_RCL5.nii.gz\n",
      "Fixed labels in /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4988_RCL5.nii.gz: Removed [28.0]\n",
      "Fixing labels in: /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4990_RCL5.nii.gz\n",
      "Fixed labels in /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4990_RCL5.nii.gz: Removed [28.0]\n",
      "Fixing labels in: /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4993_RCL5.nii.gz\n",
      "Fixed labels in /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4993_RCL5.nii.gz: Removed [28.0]\n",
      "Fixing labels in: /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4995_RCL5.nii.gz\n",
      "Fixed labels in /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4995_RCL5.nii.gz: Removed [28.0]\n",
      "Fixing labels in: /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4996_RCL5.nii.gz\n",
      "Fixed labels in /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4996_RCL5.nii.gz: Removed [28.0]\n",
      "Fixing labels in: /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4997_RCL5.nii.gz\n",
      "Fixed labels in /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG4997_RCL5.nii.gz: Removed [28.0]\n"
     ]
    }
   ],
   "source": [
    "# Function to extract labels from .nrrd\n",
    "def extract_labels_from_nrrd(folder_path):\n",
    "    label_dict = {\"background\": 0}\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".seg.nrrd\"):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            data, header = nrrd.read(file_path)\n",
    "\n",
    "            # Extract segment numbers and names\n",
    "            for key, value in header.items():\n",
    "                if key.endswith(\"_Name\"):\n",
    "                    match = re.match(r\"Segment(\\d+)\", key)\n",
    "                    if match:\n",
    "                        segment_number = int(match.group(1))\n",
    "                        if value.lower() != \"mask\":  # Exclude \"mask\"\n",
    "                            label_dict[value] = segment_number\n",
    "\n",
    "    return label_dict\n",
    "\n",
    "# Extract label mapping\n",
    "labels = extract_labels_from_nrrd(GT_TRAINING_LABELS_PATH)\n",
    "valid_labels = list(labels.values())  # Get expected label numbers\n",
    "\n",
    "# Function to re-map incorrect labels in nii.gz files\n",
    "def remap_labels(nii_path):\n",
    "    nii = nib.load(nii_path)\n",
    "    label_data = nii.get_fdata()\n",
    "\n",
    "    # Check for unexpected labels\n",
    "    unique_labels = np.unique(label_data)\n",
    "    unexpected_labels = [l for l in unique_labels if l not in valid_labels and l != 0]\n",
    "\n",
    "    if unexpected_labels:\n",
    "        print(f\"Fixing labels in: {nii_path}\")\n",
    "        \n",
    "        # Replace unexpected labels with 0 (or correct mapping)\n",
    "        fixed_label_data = np.where(np.isin(label_data, unexpected_labels), 0, label_data)\n",
    "        \n",
    "        # Save corrected label file\n",
    "        fixed_nii = nib.Nifti1Image(fixed_label_data, affine=nii.affine, header=nii.header)\n",
    "        nib.save(fixed_nii, nii_path)\n",
    "        print(f\"Fixed labels in {nii_path}: Removed {unexpected_labels}\")\n",
    "\n",
    "# Apply fix to all `.nii.gz` files\n",
    "for nii_file in os.listdir(GT_TRAINING_DATASET_PATH):\n",
    "    if nii_file.endswith(\".nii.gz\"):\n",
    "        remap_labels(os.path.join(GT_TRAINING_DATASET_PATH, nii_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape match of volume and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Found: NG2561\n",
      "  Image shape: (317, 734, 401)\n",
      "  Segmentation shape: (317, 734, 401)\n",
      "----------------------------------------\n",
      "Match Found: NG2562\n",
      "  Image shape: (299, 784, 409)\n",
      "  Segmentation shape: (299, 784, 409)\n",
      "----------------------------------------\n",
      "Match Found: NG2563\n",
      "  Image shape: (310, 760, 370)\n",
      "  Segmentation shape: (310, 760, 370)\n",
      "----------------------------------------\n",
      "Match Found: NG2564\n",
      "  Image shape: (313, 776, 378)\n",
      "  Segmentation shape: (313, 776, 378)\n",
      "----------------------------------------\n",
      "Match Found: NG2565\n",
      "  Image shape: (313, 797, 382)\n",
      "  Segmentation shape: (313, 797, 382)\n",
      "----------------------------------------\n",
      "Match Found: NG4988\n",
      "  Image shape: (318, 847, 386)\n",
      "  Segmentation shape: (319, 847, 387)\n",
      "----------------------------------------\n",
      "Match Found: NG4990\n",
      "  Image shape: (329, 845, 422)\n",
      "  Segmentation shape: (330, 846, 423)\n",
      "----------------------------------------\n",
      "Match Found: NG4993\n",
      "  Image shape: (325, 865, 410)\n",
      "  Segmentation shape: (327, 866, 411)\n",
      "----------------------------------------\n",
      "Match Found: NG4995\n",
      "  Image shape: (310, 812, 388)\n",
      "  Segmentation shape: (310, 812, 388)\n",
      "----------------------------------------\n",
      "Match Found: NG4996\n",
      "  Image shape: (337, 887, 432)\n",
      "  Segmentation shape: (338, 887, 432)\n",
      "----------------------------------------\n",
      "Match Found: NG4997\n",
      "  Image shape: (334, 880, 417)\n",
      "  Segmentation shape: (336, 882, 419)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# To check the shape match without saving\n",
    "\n",
    "# Define paths\n",
    "image_dir = TRAINING_DATASET_PATH\n",
    "label_dir = GT_TRAINING_DATASET_PATH\n",
    "\n",
    "\n",
    "# Get all image and label files\n",
    "image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(\".nii.gz\")])\n",
    "label_files = sorted([f for f in os.listdir(label_dir) if f.endswith(\".nii.gz\")])\n",
    "\n",
    "# Extract base names before \"_\" (e.g., NG2561)\n",
    "def extract_base_name(filename):\n",
    "    match = re.match(r\"(NG\\d+)\", filename)  # Match pattern like NG2561\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Create a mapping of base names to filenames\n",
    "image_dict = {extract_base_name(f): f for f in image_files}\n",
    "label_dict = {extract_base_name(f): f for f in label_files}\n",
    "\n",
    "# Check matching images and segmentations\n",
    "for base_name in image_dict.keys():\n",
    "    if base_name in label_dict:\n",
    "        # Load image and segmentation\n",
    "        img_path = os.path.join(image_dir, image_dict[base_name])\n",
    "        seg_path = os.path.join(label_dir, label_dict[base_name])\n",
    "\n",
    "        img = nib.load(img_path).get_fdata()\n",
    "        seg = nib.load(seg_path).get_fdata()\n",
    "\n",
    "        # Print shapes\n",
    "        print(f\"Match Found: {base_name}\")\n",
    "        print(\"  Image shape:\", img.shape)\n",
    "        print(\"  Segmentation shape:\", seg.shape)\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nibabel as nib\n",
    "\n",
    "# img = nib.load('dataset/nnUNet_raw_data/Dataset004_first/imagesTr/NG2561_RCL5_0000.nii.gz')\n",
    "# seg = nib.load('dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG2561_RCL5.nii.gz')\n",
    "\n",
    "\n",
    "# print(\"Image shape:\", img.shape)\n",
    "# print(\"Segmentation shape:\", seg.shape)\n",
    "\n",
    "# print(\"Image voxel spacing:\", img.header.get_zooms())\n",
    "# print(\"Segmentation voxel spacing:\", seg.header.get_zooms())\n",
    "\n",
    "# print(\"Image affine:\\n\", img.affine)\n",
    "# print(\"Segmentation affine:\\n\", seg.affine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed & Saved: NG2561\n",
      "  New Image shape: (317, 734, 401)\n",
      "  New Segmentation shape: (317, 734, 401)\n",
      "----------------------------------------\n",
      "Fixed & Saved: NG2562\n",
      "  New Image shape: (299, 784, 409)\n",
      "  New Segmentation shape: (299, 784, 409)\n",
      "----------------------------------------\n",
      "Fixed & Saved: NG2563\n",
      "  New Image shape: (310, 760, 370)\n",
      "  New Segmentation shape: (310, 760, 370)\n",
      "----------------------------------------\n",
      "Fixed & Saved: NG2564\n",
      "  New Image shape: (313, 776, 378)\n",
      "  New Segmentation shape: (313, 776, 378)\n",
      "----------------------------------------\n",
      "Fixed & Saved: NG2565\n",
      "  New Image shape: (313, 797, 382)\n",
      "  New Segmentation shape: (313, 797, 382)\n",
      "----------------------------------------\n",
      "Fixed & Saved: NG4988\n",
      "  New Image shape: (319, 847, 387)\n",
      "  New Segmentation shape: (319, 847, 387)\n",
      "----------------------------------------\n",
      "Fixed & Saved: NG4990\n",
      "  New Image shape: (330, 846, 423)\n",
      "  New Segmentation shape: (330, 846, 423)\n",
      "----------------------------------------\n",
      "Fixed & Saved: NG4993\n",
      "  New Image shape: (327, 866, 411)\n",
      "  New Segmentation shape: (327, 866, 411)\n",
      "----------------------------------------\n",
      "Fixed & Saved: NG4995\n",
      "  New Image shape: (310, 812, 388)\n",
      "  New Segmentation shape: (310, 812, 388)\n",
      "----------------------------------------\n",
      "Fixed & Saved: NG4996\n",
      "  New Image shape: (338, 887, 432)\n",
      "  New Segmentation shape: (338, 887, 432)\n",
      "----------------------------------------\n",
      "Fixed & Saved: NG4997\n",
      "  New Image shape: (336, 882, 419)\n",
      "  New Segmentation shape: (336, 882, 419)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# To save padded shapes\n",
    "\n",
    "# Define paths\n",
    "image_dir = TRAINING_DATASET_PATH\n",
    "label_dir = GT_TRAINING_DATASET_PATH\n",
    "\n",
    "# Get all image and label files\n",
    "image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(\".nii.gz\")])\n",
    "label_files = sorted([f for f in os.listdir(label_dir) if f.endswith(\".nii.gz\")])\n",
    "\n",
    "# Extract base names before \"_\" (e.g., NG2561)\n",
    "def extract_base_name(filename):\n",
    "    match = re.match(r\"(NG\\d+)\", filename)  # Match pattern like NG2561\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Create a mapping of base names to filenames\n",
    "image_dict = {extract_base_name(f): f for f in image_files}\n",
    "label_dict = {extract_base_name(f): f for f in label_files}\n",
    "\n",
    "def pad_to_match(image, segmentation):\n",
    "    \"\"\"\n",
    "    Pads the smaller volume to match the shape of the larger volume.\n",
    "    Assumes only the first dimension (depth) varies.\n",
    "    \"\"\"\n",
    "    img_shape = np.array(image.shape)\n",
    "    seg_shape = np.array(segmentation.shape)\n",
    "\n",
    "    if np.array_equal(img_shape, seg_shape):\n",
    "        return image, segmentation  # Already matching\n",
    "\n",
    "    pad_width = [(0, 0), (0, 0), (0, 0)]  # Default (no padding)\n",
    "\n",
    "    for i in range(3):  # Iterate over dimensions\n",
    "        diff = seg_shape[i] - img_shape[i]\n",
    "        if diff > 0:  # Image is smaller\n",
    "            pad_width[i] = (0, diff)\n",
    "        elif diff < 0:  # Segmentation is smaller\n",
    "            pad_width[i] = (0, -diff)\n",
    "\n",
    "    if img_shape[0] < seg_shape[0]:  # Image is smaller in depth\n",
    "        image = np.pad(image, pad_width, mode='constant', constant_values=0)\n",
    "    elif img_shape[0] > seg_shape[0]:  # Segmentation is smaller in depth\n",
    "        segmentation = np.pad(segmentation, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "    return image, segmentation\n",
    "\n",
    "# Loop through matched images and segmentations\n",
    "for base_name in image_dict.keys():\n",
    "    if base_name in label_dict:\n",
    "        img_path = os.path.join(image_dir, image_dict[base_name])\n",
    "        seg_path = os.path.join(label_dir, label_dict[base_name])\n",
    "\n",
    "        # Load files\n",
    "        img_nii = nib.load(img_path)\n",
    "        seg_nii = nib.load(seg_path)\n",
    "\n",
    "        img = img_nii.get_fdata()\n",
    "        seg = seg_nii.get_fdata()\n",
    "\n",
    "        # Pad to match sizes\n",
    "        img, seg = pad_to_match(img, seg)\n",
    "\n",
    "        # Save the fixed files\n",
    "        nib.save(nib.Nifti1Image(img, img_nii.affine, img_nii.header), img_path)\n",
    "        nib.save(nib.Nifti1Image(seg, seg_nii.affine, seg_nii.header), seg_path)\n",
    "\n",
    "        print(f\"Fixed & Saved: {base_name}\")\n",
    "        print(\"  New Image shape:\", img.shape)\n",
    "        print(\"  New Segmentation shape:\", seg.shape)\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nibabel as nib\n",
    "# import numpy as np\n",
    "\n",
    "# # Load segmentation\n",
    "# seg = nib.load('dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG2561_RCL5.nii.gz')\n",
    "# seg_data = seg.get_fdata()\n",
    "\n",
    "# # Pad with 13 slices (assuming missing slices at the top)\n",
    "# padding = ((13, 0), (0, 0), (0, 0))  # Add 13 slices at the top\n",
    "# padded_seg_data = np.pad(seg_data, padding, mode='constant', constant_values=0)\n",
    "\n",
    "# # Save the fixed segmentation\n",
    "# fixed_seg = nib.Nifti1Image(padded_seg_data, seg.affine, seg.header)\n",
    "# nib.save(fixed_seg, 'dataset/nnUNet_raw_data/Dataset004_first/labelsTr/NG2561_RCL5.nii.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: nnUNet_raw=/beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_raw_data\n",
      "env: nnUNet_preprocessed=/beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_preprocessed\n",
      "env: nnUNet_results=/beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "%env nnUNet_raw=$nnUNet_raw\n",
    "%env nnUNet_preprocessed=$nnUNet_preprocessed\n",
    "%env nnUNet_results=$nnUNet_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset004_first\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "100%|███████████████████████████████████████████| 11/11 [00:23<00:00,  2.14s/it]\n",
      "Experiment planning...\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.03 1.03 1.03]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [386.40776699 775.72815534 304.85436893]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.0609 1.0609 1.0609]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [375.15317184 753.1341314  295.97511547]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.092727 1.092727 1.092727]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [364.22638042 731.19818582 287.35448104]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.12550881 1.12550881 1.12550881]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [353.61784507 709.90115128 278.98493305]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.15927407 1.15927407 1.15927407]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [343.31829618 689.22441872 270.8591583 ]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.1940523 1.1940523 1.1940523]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [333.31873416 669.14992109 262.9700566 ]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.22987387 1.22987387 1.22987387]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [323.61042151 649.66011756 255.31073456]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.26677008 1.26677008 1.26677008]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [314.18487526 630.73797822 247.87449957]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.30477318 1.30477318 1.30477318]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [305.03385947 612.36696914 240.65485396]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.34391638 1.34391638 1.34391638]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [296.14937813 594.531038   233.64548928]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.38423387 1.38423387 1.38423387]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [287.52366809 577.2146     226.84028085]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.42576089 1.42576089 1.42576089]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [279.14919232 560.40252427 220.23328238]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.46853371 1.46853371 1.46853371]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [271.01863332 544.08012065 213.81872076]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.51258972 1.51258972 1.51258972]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [263.12488672 528.23312685 207.59099103]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.55796742 1.55796742 1.55796742]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [255.46105506 512.84769597 201.54465148]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.60470644 1.60470644 1.60470644]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [248.02044181 497.91038444 195.67441892]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.65284763 1.65284763 1.65284763]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [240.79654545 483.40814023 189.975164  ]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.70243306 1.70243306 1.70243306]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [233.78305383 469.32829149 184.44190679]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.75350605 1.75350605 1.75350605]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [226.97383867 455.65853542 179.06981242]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.80611123 1.80611123 1.80611123]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [220.36295017 442.38692759 173.85418681]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.86029457 1.86029457 1.86029457]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [213.94461181 429.50187145 168.79047264]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.91610341 1.91610341 1.91610341]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [207.71321535 416.99210821 163.87424528]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.97358651 1.97358651 1.97358651]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [201.66331588 404.846707   159.10120901]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.03279411 2.03279411 2.03279411]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [195.78962706 393.05505534 154.46719321]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.09377793 2.09377793 2.09377793]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [190.08701657 381.60684984 149.96814875]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.15659127 2.15659127 2.15659127]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [184.55050152 370.49208722 145.60014442]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.22128901 2.22128901 2.22128901]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [179.17524419 359.70105556 141.35936351]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.28792768 2.28792768 2.28792768]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [173.95654776 349.22432578 137.2421005 ]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.35656551 2.35656551 2.35656551]. \n",
      "Current patch size: (112, 224, 80). \n",
      "Current median shape: [168.8898522  339.05274348 133.24475776]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': (896, 320), 'median_image_size_in_voxels': array([799., 314.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 1)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D lowres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (112, 224, 80), 'median_image_size_in_voxels': (169, 339, 133), 'spacing': array([2.35656551, 2.35656551, 2.35656551]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 1)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'}\n",
      "\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (112, 224, 80), 'median_image_size_in_voxels': array([398., 799., 314.]), 'spacing': array([1., 1., 1.]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 1)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Plans were saved to /beegfs/data/work/shared/ngmm/scripts/Beyza_Zayim/Taibur/ngmm-nnunet/dataset/nnUNet_preprocessed/Dataset004_first/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset004_first\n",
      "Configuration: 2d...\n",
      "100%|███████████████████████████████████████████| 11/11 [01:25<00:00,  7.77s/it]\n",
      "Configuration: 3d_fullres...\n",
      "100%|███████████████████████████████████████████| 11/11 [02:10<00:00, 11.89s/it]\n",
      "Configuration: 3d_lowres...\n",
      "100%|███████████████████████████████████████████| 11/11 [01:39<00:00,  9.04s/it]\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_plan_and_preprocess -d 4 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load gcc 9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "module load gcc/9.1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
